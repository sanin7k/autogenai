# ğŸ”® autogenai

âš ï¸ This is an early-stage SDK. Interfaces and behaviors may change in minor releases.

**Early-stage unified SDK for LLMs like OpenAI, Gemini and more. â€” Simple, Pluggable, and Ready for Production**

---

## âœ¨ Features

- ğŸ§  Unified interface for LLMs (OpenAI, Gemini, etc.)
- ğŸ› ï¸ Automatically loads from `.env` (`OPENAI_API_KEY`, `GEMINI_API_KEY`, `LLM_ENGINE`, `DEFAULT_OPENAI_MODEL`, `DEFAULT_GEMINI_MODEL`)
- ğŸš¨ Built-in error handling: `APIMissingError`, `LLMResponseError`
- ğŸ§ª 100% test coverage with `pytest`
- ğŸ”§ CLI included for quick interaction
- ğŸ“¦ PyPI-ready structure with semantic versioning

---

## ğŸ“¦ Installation

```bash
pip install autogenai

```
Or, from source:
```bash
git clone https://github.com/sanin7k/autogenai-sdk.git
cd autogenai
pip install .
```

---

## âš™ï¸ Configuration

Create a .env file in your project root:
```env
# Required (one or both depending on engine used)
OPENAI_API_KEY=your_openai_key
GEMINI_API_KEY=your_google_key

# Optional engine & model settings
LLM_ENGINE=openai  # or gemini
DEFAULT_OPENAI_MODEL=gpt-3.5-turbo
DEFAULT_GEMINI_MODEL=gemini-1.5-pro
```
If a required API key is missing, APIMissingError will be raised at runtime.

---

## ğŸš€ Usage (Python)
```python
from autogenai.core.factory import LLMFactory

engine = LLMFactory.create() # uses LLM_ENGINE from .env or defaults to Gemini
response = engine.chat("Tell me a joke")
print(response)

```

---

## ğŸ§ª Testing

Run all tests:

```bash
pytest
```
Includes mocks for external calls and full coverage for OpenAIEngine, GeminiEngine, and factory.

---

## ğŸ’» CLI Usage

You can also use the SDK via command line:
```bash
autogenai chat "What's the capital of France?"
```

Or for Gemini specifically:

```bash
autogenai chat "What's the capital of France?" --engine "gemini"
```

---

## ğŸ“‚ Project Structure

```bash
autogenai-sdk/
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ openai_chat.py
â”‚   â”œâ”€â”€ sdk_chat.py
â”‚   â”œâ”€â”€ sdk_cli.py
â”‚   â””â”€â”€ simple_chat.py
â”œâ”€â”€ src/autogenai/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ factory.py
â”‚   â”‚   â”œâ”€â”€ gemini_engine.py
â”‚   â”‚   â””â”€â”€ openai_engine.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ errors.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â””â”€â”€ tools.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_factory.py
â”‚   â””â”€â”€ test_openai.py
â”œâ”€â”€ .env
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ pyproject.toml

```

---

## ğŸ“– Error Handling

**APIMissingError**

Raised when API key is not found in .env.
```python
raise MissingAPIKeyError("Missing OpenAI API key.")
```

**LLMResponseError**

Raised when the API responds with an error (like 429 or 401).
```python
raise LLMResponseError("API failed", status_code=429, response_data={...})

```

---

## ğŸ”¢ Semantic Versioning

This SDK follows SemVer:
- MAJOR â€“ breaking changes
- MINOR â€“ new features, backward-compatible
- PATCH â€“ bug fixes

Current version: 0.1.0

---

## ğŸ™Œ Contributing

1. Fork this repo
2. Create your feature branch (git checkout -b feat/my-feature)
3. Commit changes (git commit -am 'add cool feature')
4. Push to branch (git push origin feat/my-feature)
5. Open a pull request ğŸš€

---

## ğŸ“ License
MIT License Â© 2025 Sanin K